#!/usr/bin/env python3
"""
æµ‹è¯•è®ºå›ç½‘é¡µç»“æ„å’Œç­›é€‰æœºåˆ¶çš„è„šæœ¬
"""

import asyncio
import aiohttp
from bs4 import BeautifulSoup

async def analyze_forum_structure():
    """åˆ†æè®ºå›ç½‘é¡µç»“æ„"""
    print("=== åˆ†æ Unikorn è®ºå›ç½‘é¡µç»“æ„ ===\n")
    
    forum_url = "https://unikorn.axfff.com/forum"
    
    async with aiohttp.ClientSession(
        timeout=aiohttp.ClientTimeout(total=30),
        headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
    ) as session:
        try:
            async with session.get(forum_url) as response:
                if response.status != 200:
                    print(f"âŒ è·å–é¡µé¢å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
                    return
                
                html = await response.text()
                soup = BeautifulSoup(html, 'html.parser')
                
                print("1. é¡µé¢åŸºæœ¬ä¿¡æ¯")
                print("=" * 40)
                title = soup.find('title')
                print(f"é¡µé¢æ ‡é¢˜: {title.text if title else 'æœªæ‰¾åˆ°'}")
                
                # æŸ¥æ‰¾é¡µé¢ä¸»è¦å®¹å™¨
                print(f"\n2. ä¸»è¦å®¹å™¨ç»“æ„")
                print("=" * 40)
                
                posts_container = soup.find('div', class_='posts-container')
                if posts_container:
                    print("âœ… æ‰¾åˆ° posts-container")
                    
                    page_title = posts_container.find('h1', class_='page-title')
                    if page_title:
                        print(f"é¡µé¢æ ‡é¢˜: {page_title.text.strip()}")
                    
                    posts_list = posts_container.find('div', class_='posts-list')
                    if posts_list:
                        print(f"posts-list å†…å®¹: {len(posts_list.find_all())} ä¸ªå­å…ƒç´ ")
                        print(f"posts-list HTML: {str(posts_list)[:200]}...")
                else:
                    print("âŒ æœªæ‰¾åˆ° posts-container")
                
                # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„å¸–å­é“¾æ¥
                print(f"\n3. æ‰€æœ‰ <a> æ ‡ç­¾åˆ†æ")
                print("=" * 40)
                
                all_links = soup.find_all('a', href=True)
                print(f"æ€»å…±æ‰¾åˆ° {len(all_links)} ä¸ªé“¾æ¥")
                
                for i, link in enumerate(all_links, 1):
                    href = link.get('href', '')
                    text = link.get_text(strip=True)
                    classes = link.get('class', [])
                    
                    print(f"{i:2d}. href='{href}' text='{text}' class={classes}")
                
                # æŸ¥æ‰¾åŒ…å«"å‘å¸–"çš„å…ƒç´ 
                print(f"\n4. å‘å¸–ç›¸å…³å…ƒç´ ")
                print("=" * 40)
                
                post_buttons = soup.find_all(text=lambda t: t and 'å‘å¸–' in t)
                for i, button_text in enumerate(post_buttons, 1):
                    parent = button_text.parent
                    print(f"{i}. æ–‡æœ¬: '{button_text.strip()}'")
                    print(f"   çˆ¶å…ƒç´ : {parent.name if parent else 'None'}")
                    print(f"   çˆ¶å…ƒç´ ç±»: {parent.get('class', []) if parent else []}")
                    print(f"   å®Œæ•´HTML: {str(parent)[:150]}...")
                    print()
                
                # æµ‹è¯•æˆ‘ä»¬çš„ç­›é€‰é€»è¾‘
                print(f"\n5. æµ‹è¯•ç­›é€‰é€»è¾‘")
                print("=" * 40)
                
                # æµ‹è¯•æ–‡æœ¬ç­›é€‰
                test_texts = [
                    "æˆ‘è¦å‘å¸–",
                    "å‘å¸–",
                    "è®ºå›æ–‡ç« ",
                    "æ’åºæ–¹å¼",
                    "ä¸Šä¸€é¡µ",
                    "ä¸‹ä¸€é¡µ",
                    "ç™»å½•",
                    "æ³¨å†Œ"
                ]
                
                excluded_keywords = [
                    'å‘å¸–', 'ç™»å½•', 'æ³¨å†Œ', 'æ’åº', 'ç­›é€‰', 'é¡µ', 'èœå•', 
                    'å¯¼èˆª', 'æœç´¢', 'è®¾ç½®', 'å¸®åŠ©', 'å…³äº'
                ]
                
                def is_button_text(text):
                    if not text or len(text.strip()) < 2:
                        return True
                    
                    # å¸¸è§æŒ‰é’®æ–‡æœ¬æ¨¡å¼
                    button_patterns = [
                        r'^(ç‚¹å‡»|æŒ‰é’®|ç¡®å®š|å–æ¶ˆ|æäº¤|é‡ç½®|ä¿å­˜|åˆ é™¤|ç¼–è¾‘|ä¿®æ”¹|æ·»åŠ |æ–°å¢)',
                        r'(å‘å¸–|ç™»å½•|æ³¨å†Œ|æœç´¢|ç­›é€‰|æ’åº|åˆ‡æ¢|å±•å¼€|æ”¶èµ·)$',
                        r'^(ä¸Šä¸€é¡µ|ä¸‹ä¸€é¡µ|é¦–é¡µ|æœ«é¡µ|ç¬¬\s*\d+\s*é¡µ)',
                        r'^(æ›´å¤š|æŸ¥çœ‹|è¯¦æƒ…|å±•ç¤º|æ˜¾ç¤º|éšè—)$'
                    ]
                    
                    import re
                    text_clean = text.strip()
                    for pattern in button_patterns:
                        if re.search(pattern, text_clean):
                            return True
                    
                    return False
                
                def is_excluded_content(text):
                    if not text:
                        return True
                    
                    text_lower = text.lower().strip()
                    return any(keyword.lower() in text_lower for keyword in excluded_keywords)
                
                print("æµ‹è¯•æŒ‰é’®æ–‡æœ¬æ£€æµ‹:")
                for text in test_texts:
                    is_button = is_button_text(text)
                    is_excluded = is_excluded_content(text)
                    print(f"  '{text}' -> æŒ‰é’®: {is_button}, æ’é™¤: {is_excluded}")
                
                # åˆ†æJavaScriptåŠ è½½çš„æ•°æ®
                print(f"\n6. JavaScriptæ•°æ®åˆ†æ")
                print("=" * 40)
                
                scripts = soup.find_all('script')
                nuxt_data = None
                for script in scripts:
                    if script.get('id') == '__NUXT_DATA__':
                        nuxt_data = script.string
                        break
                
                if nuxt_data:
                    print("âœ… æ‰¾åˆ° NUXT æ•°æ®")
                    print(f"æ•°æ®é•¿åº¦: {len(nuxt_data)} å­—ç¬¦")
                    # å°è¯•æŸ¥æ‰¾ä¸å¸–å­ç›¸å…³çš„æ•°æ®
                    if '"posts"' in nuxt_data or '"articles"' in nuxt_data:
                        print("âœ… æ•°æ®ä¸­åŒ…å«å¸–å­ä¿¡æ¯")
                    else:
                        print("âš ï¸ æ•°æ®ä¸­æœªç›´æ¥æ‰¾åˆ°å¸–å­ä¿¡æ¯")
                else:
                    print("âŒ æœªæ‰¾åˆ° NUXT æ•°æ®")
                
                print(f"\n7. æ€»ç»“")
                print("=" * 40)
                print("ğŸ” å‘ç°çš„é—®é¢˜:")
                print("1. è¿™æ˜¯ä¸€ä¸ª Nuxt.js SPAï¼Œå¸–å­å†…å®¹é€šè¿‡ JavaScript åŠ¨æ€åŠ è½½")
                print("2. é™æ€HTMLä¸­åªåŒ…å«é¡µé¢æ¡†æ¶ï¼Œæ²¡æœ‰å®é™…å¸–å­å†…å®¹")
                print("3. 'æˆ‘è¦å‘å¸–' æŒ‰é’®ç¡®å®å­˜åœ¨äºé™æ€HTMLä¸­")
                print("4. éœ€è¦ç­‰å¾… JavaScript æ‰§è¡Œæˆ–ä½¿ç”¨APIè·å–å®é™…å¸–å­æ•°æ®")
                
                print(f"\nğŸ’¡ å»ºè®®çš„è§£å†³æ–¹æ¡ˆ:")
                print("1. å¢å¼ºæŒ‰é’®å’Œå¯¼èˆªå…ƒç´ çš„ç­›é€‰é€»è¾‘")
                print("2. æ·»åŠ å¯¹ç©ºå†…å®¹çš„æ£€æµ‹")
                print("3. è€ƒè™‘ä½¿ç”¨ Selenium æˆ–å…¶ä»–æ¸²æŸ“å¼•æ“")
                print("4. æŸ¥æ‰¾æ˜¯å¦æœ‰ç›´æ¥çš„APIç«¯ç‚¹")
                
        except Exception as e:
            print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")

if __name__ == "__main__":
    asyncio.run(analyze_forum_structure())
