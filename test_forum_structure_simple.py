#!/usr/bin/env python3
"""
ä½¿ç”¨å†…ç½®åº“åˆ†æè®ºå›ç½‘é¡µç»“æ„çš„è„šæœ¬
"""

import urllib.request
import urllib.error
import re
from html import unescape

def analyze_forum_structure():
    """åˆ†æè®ºå›ç½‘é¡µç»“æ„"""
    print("=== åˆ†æ Unikorn è®ºå›ç½‘é¡µç»“æ„ ===\n")
    
    forum_url = "https://unikorn.axfff.com/forum"
    
    try:
        # åˆ›å»ºè¯·æ±‚
        req = urllib.request.Request(
            forum_url,
            headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
        )
        
        with urllib.request.urlopen(req, timeout=10) as response:
            if response.status != 200:
                print(f"âŒ è·å–é¡µé¢å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
                return
            
            html = response.read().decode('utf-8')
            
            print("1. é¡µé¢åŸºæœ¬ä¿¡æ¯")
            print("=" * 40)
            
            # æŸ¥æ‰¾é¡µé¢æ ‡é¢˜
            title_match = re.search(r'<title>(.*?)</title>', html, re.IGNORECASE)
            if title_match:
                print(f"é¡µé¢æ ‡é¢˜: {unescape(title_match.group(1))}")
            
            # æŸ¥æ‰¾è®ºå›æ–‡ç« æ ‡é¢˜
            page_title_match = re.search(r'class="page-title"[^>]*>(.*?)</h1>', html, re.IGNORECASE | re.DOTALL)
            if page_title_match:
                print(f"è®ºå›æ ‡é¢˜: {unescape(re.sub(r'<[^>]*>', '', page_title_match.group(1)).strip())}")
            
            print(f"\n2. å¯»æ‰¾æ‰€æœ‰é“¾æ¥")
            print("=" * 40)
            
            # æŸ¥æ‰¾æ‰€æœ‰ <a> æ ‡ç­¾
            link_pattern = r'<a\s+[^>]*href=["\'](.*?)["\'][^>]*>(.*?)</a>'
            links = re.findall(link_pattern, html, re.IGNORECASE | re.DOTALL)
            
            print(f"æ€»å…±æ‰¾åˆ° {len(links)} ä¸ªé“¾æ¥")
            
            for i, (href, text) in enumerate(links[:20], 1):  # åªæ˜¾ç¤ºå‰20ä¸ª
                clean_text = unescape(re.sub(r'<[^>]*>', '', text).strip())
                if clean_text:  # åªæ˜¾ç¤ºæœ‰æ–‡æœ¬çš„é“¾æ¥
                    print(f"{i:2d}. href='{href}' text='{clean_text[:50]}{'...' if len(clean_text) > 50 else ''}'")
            
            if len(links) > 20:
                print(f"... è¿˜æœ‰ {len(links) - 20} ä¸ªé“¾æ¥")
            
            print(f"\n3. æŸ¥æ‰¾å‘å¸–ç›¸å…³å†…å®¹")
            print("=" * 40)
            
            # æŸ¥æ‰¾åŒ…å«"å‘å¸–"çš„å†…å®¹
            post_pattern = r'[^>]*å‘å¸–[^<]*'
            post_matches = re.findall(post_pattern, html, re.IGNORECASE)
            
            print(f"åŒ…å«'å‘å¸–'çš„æ–‡æœ¬: {len(post_matches)} ä¸ª")
            for i, match in enumerate(post_matches, 1):
                clean_match = unescape(re.sub(r'<[^>]*>', '', match).strip())
                if clean_match:
                    print(f"{i}. '{clean_match}'")
            
            # æŸ¥æ‰¾"æˆ‘è¦å‘å¸–"æŒ‰é’®
            post_button_pattern = r'<a[^>]*href=["\'][^"\']*postMessage[^"\']*["\'][^>]*>(.*?)</a>'
            post_button_matches = re.findall(post_button_pattern, html, re.IGNORECASE | re.DOTALL)
            
            print(f"\nå‘å¸–æŒ‰é’®: {len(post_button_matches)} ä¸ª")
            for i, match in enumerate(post_button_matches, 1):
                clean_match = unescape(re.sub(r'<[^>]*>', '', match).strip())
                print(f"{i}. '{clean_match}'")
            
            print(f"\n4. æŸ¥æ‰¾å¸–å­å®¹å™¨")
            print("=" * 40)
            
            # æŸ¥æ‰¾posts-listå®¹å™¨
            posts_list_pattern = r'<div[^>]*class="posts-list"[^>]*>(.*?)</div>'
            posts_list_matches = re.findall(posts_list_pattern, html, re.IGNORECASE | re.DOTALL)
            
            if posts_list_matches:
                print(f"æ‰¾åˆ° posts-list å®¹å™¨: {len(posts_list_matches)} ä¸ª")
                for i, content in enumerate(posts_list_matches, 1):
                    clean_content = re.sub(r'<[^>]*>', '', content).strip()
                    print(f"{i}. å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
                    print(f"   æ¸…ç†åå†…å®¹: '{clean_content[:100]}{'...' if len(clean_content) > 100 else ''}'")
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºæˆ–åªåŒ…å«æ³¨é‡Š
                    if not clean_content or clean_content.isspace():
                        print("   âŒ å®¹å™¨ä¸ºç©º")
                    elif "<!--" in content and "-->" in content:
                        print("   âš ï¸ å®¹å™¨ä¸»è¦åŒ…å«HTMLæ³¨é‡Š")
            else:
                print("âŒ æœªæ‰¾åˆ° posts-list å®¹å™¨")
            
            print(f"\n5. åˆ†é¡µä¿¡æ¯")
            print("=" * 40)
            
            # æŸ¥æ‰¾åˆ†é¡µä¿¡æ¯
            pagination_pattern = r'ç¬¬\s*(\d+)\s*é¡µ[^ç¬¬]*å…±\s*(\d+)\s*é¡µ'
            pagination_matches = re.findall(pagination_pattern, html, re.IGNORECASE)
            
            if pagination_matches:
                current_page, total_pages = pagination_matches[0]
                print(f"å½“å‰é¡µ: {current_page}, æ€»é¡µæ•°: {total_pages}")
            else:
                print("æœªæ‰¾åˆ°åˆ†é¡µä¿¡æ¯")
            
            print(f"\n6. JavaScript æ•°æ®åˆ†æ")
            print("=" * 40)
            
            # æŸ¥æ‰¾NUXTæ•°æ®
            nuxt_data_pattern = r'<script[^>]*id="__NUXT_DATA__"[^>]*>(.*?)</script>'
            nuxt_data_matches = re.findall(nuxt_data_pattern, html, re.IGNORECASE | re.DOTALL)
            
            if nuxt_data_matches:
                data = nuxt_data_matches[0].strip()
                print(f"âœ… æ‰¾åˆ° NUXT æ•°æ®ï¼Œé•¿åº¦: {len(data)} å­—ç¬¦")
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«å¸–å­ç›¸å…³æ•°æ®
                if '"posts"' in data.lower() or '"articles"' in data.lower():
                    print("âœ… æ•°æ®ä¸­å¯èƒ½åŒ…å«å¸–å­ä¿¡æ¯")
                else:
                    print("âš ï¸ æ•°æ®ä¸­æœªå‘ç°æ˜æ˜¾çš„å¸–å­ä¿¡æ¯")
                    
                # æ˜¾ç¤ºæ•°æ®çš„å¼€å¤´éƒ¨åˆ†
                print(f"æ•°æ®å¼€å¤´: {data[:200]}...")
            else:
                print("âŒ æœªæ‰¾åˆ° NUXT æ•°æ®")
            
            print(f"\n7. ç­›é€‰é€»è¾‘æµ‹è¯•")
            print("=" * 40)
            
            # æµ‹è¯•æˆ‘ä»¬çš„ç­›é€‰å…³é”®è¯
            excluded_keywords = [
                'å‘å¸–', 'ç™»å½•', 'æ³¨å†Œ', 'æ’åº', 'ç­›é€‰', 'é¡µ', 'èœå•', 
                'å¯¼èˆª', 'æœç´¢', 'è®¾ç½®', 'å¸®åŠ©', 'å…³äº'
            ]
            
            def is_excluded_content(text):
                if not text:
                    return True
                text_lower = text.lower().strip()
                return any(keyword.lower() in text_lower for keyword in excluded_keywords)
            
            test_texts = [
                "æˆ‘è¦å‘å¸–",
                "è®ºå›æ–‡ç« ", 
                "æ’åºæ–¹å¼ï¼š",
                "ä¸Šä¸€é¡µ",
                "ä¸‹ä¸€é¡µ",
                "é¦–é¡µ",
                "ç™»å½•",
                "è¿™æ˜¯ä¸€ä¸ªçœŸå®çš„å¸–å­æ ‡é¢˜"
            ]
            
            print("ç­›é€‰å…³é”®è¯æµ‹è¯•:")
            for text in test_texts:
                excluded = is_excluded_content(text)
                status = "âŒ è¢«æ’é™¤" if excluded else "âœ… é€šè¿‡"
                print(f"  '{text}' -> {status}")
            
            print(f"\n8. æ€»ç»“")
            print("=" * 40)
            print("ğŸ” ä¸»è¦å‘ç°:")
            print("1. è¿™æ˜¯ä¸€ä¸ª Nuxt.js å•é¡µåº”ç”¨")
            print("2. å¸–å­åˆ—è¡¨å®¹å™¨ä¸ºç©ºï¼Œå†…å®¹é€šè¿‡ JavaScript åŠ¨æ€åŠ è½½")
            print("3. å­˜åœ¨'æˆ‘è¦å‘å¸–'æŒ‰é’®ï¼Œä¼šè¢«å½“å‰ç­›é€‰æœºåˆ¶è¯¯åˆ¤")
            print("4. åˆ†é¡µæ˜¾ç¤º'ç¬¬1é¡µï¼Œå…±1é¡µ'ï¼Œè¯´æ˜å¯èƒ½æ²¡æœ‰å¸–å­æ•°æ®")
            
            print(f"\nğŸ’¡ é—®é¢˜åŸå› :")
            print("- é™æ€HTMLä¸­æ²¡æœ‰çœŸå®å¸–å­å†…å®¹")
            print("- å½“å‰çš„BeautifulSoupåªèƒ½è§£æé™æ€HTML")
            print("- 'æˆ‘è¦å‘å¸–'æŒ‰é’®è¢«è¯¯è®¤ä¸ºæ˜¯å¸–å­é“¾æ¥")
            
            print(f"\nğŸ”§ è§£å†³æ–¹æ¡ˆ:")
            print("1. æ”¹è¿›ç­›é€‰é€»è¾‘ï¼Œæ›´å¥½åœ°è¯†åˆ«æŒ‰é’®å’Œå¯¼èˆªå…ƒç´ ")
            print("2. æ£€æŸ¥å¸–å­å®¹å™¨æ˜¯å¦ä¸ºç©º")
            print("3. è€ƒè™‘ä½¿ç”¨Seleniumç­‰å·¥å…·å¤„ç†JavaScriptæ¸²æŸ“")
            print("4. å¯»æ‰¾å¯èƒ½çš„APIç«¯ç‚¹ç›´æ¥è·å–æ•°æ®")
                
    except urllib.error.URLError as e:
        print(f"âŒ ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}")
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")

if __name__ == "__main__":
    analyze_forum_structure()
