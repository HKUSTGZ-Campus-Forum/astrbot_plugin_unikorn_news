import asyncio
import json
import os
import re
from datetime import datetime
from typing import Dict, List, Set, Optional
import aiohttp
from bs4 import BeautifulSoup

from astrbot.api.event import filter, AstrMessageEvent, MessageEventResult, MessageChain
from astrbot.api.star import Context, Star, register
from astrbot.api import logger, AstrBotConfig
import astrbot.api.message_components as Comp

@register("unikorn_news", "Assistant", "ç›‘å¬Unikornè®ºå›æ›´æ–°ï¼Œè‡ªåŠ¨æ¨é€æ–°å¸–å­åˆ°QQç¾¤", "1.0.0", "https://github.com/Soulter/astrbot_plugin_unikorn_news")
class UnikornNewsPlugin(Star):
    def __init__(self, context: Context, config: AstrBotConfig):
        super().__init__(context)
        self.config = config
        self.forum_url = "https://unikorn.axfff.com/forum"
        self.check_task = None
        self.known_posts: Set[str] = set()
        # æ•°æ®æ–‡ä»¶å­˜å‚¨åœ¨dataç›®å½•ä¸‹ï¼Œé¿å…æ’ä»¶æ›´æ–°æ—¶è¢«è¦†ç›–
        data_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "data")
        os.makedirs(data_dir, exist_ok=True)
        self.data_file = os.path.join(data_dir, "unikorn_news_data.json")
        self.session: Optional[aiohttp.ClientSession] = None
        
    async def initialize(self):
        """æ’ä»¶åˆå§‹åŒ–æ–¹æ³•"""
        try:
            logger.info("Unikorn News Plugin åˆå§‹åŒ–ä¸­...")
            
            # åˆ›å»ºHTTPä¼šè¯
            self.session = aiohttp.ClientSession(
                timeout=aiohttp.ClientTimeout(total=30),
                headers={
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                }
            )
            
            # åŠ è½½å·²çŸ¥å¸–å­
            await self.load_known_posts()
            
            # å¦‚æœå¯ç”¨äº†é€šçŸ¥åŠŸèƒ½ï¼Œå¯åŠ¨å®šæ—¶æ£€æŸ¥ä»»åŠ¡
            if self.config.get("enable_notification", True):
                await self.start_monitoring()
                
            logger.info("Unikorn News Plugin åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            logger.error(f"Unikorn News Plugin åˆå§‹åŒ–å¤±è´¥: {e}")

    async def load_known_posts(self):
        """åŠ è½½å·²çŸ¥çš„å¸–å­ID"""
        try:
            if os.path.exists(self.data_file):
                with open(self.data_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.known_posts = set(data.get('known_posts', []))
                logger.info(f"å·²åŠ è½½ {len(self.known_posts)} ä¸ªå·²çŸ¥å¸–å­")
            else:
                logger.info("æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°çš„æ•°æ®æ–‡ä»¶")
        except Exception as e:
            logger.error(f"åŠ è½½å·²çŸ¥å¸–å­å¤±è´¥: {e}")

    async def save_known_posts(self):
        """ä¿å­˜å·²çŸ¥çš„å¸–å­ID"""
        try:
            os.makedirs(os.path.dirname(self.data_file), exist_ok=True)
            data = {
                'known_posts': list(self.known_posts),
                'last_update': datetime.now().isoformat()
            }
            with open(self.data_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ä¿å­˜å·²çŸ¥å¸–å­å¤±è´¥: {e}")

    async def fetch_forum_posts(self) -> List[Dict]:
        """è·å–è®ºå›å¸–å­åˆ—è¡¨"""
        try:
            if not self.session:
                logger.error("HTTPä¼šè¯æœªåˆå§‹åŒ–")
                return []
                
            async with self.session.get(self.forum_url) as response:
                if response.status != 200:
                    logger.error(f"è·å–è®ºå›é¡µé¢å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
                    return []
                
                html = await response.text()
                soup = BeautifulSoup(html, 'html.parser')
                
                posts = []
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºNuxt.jsæˆ–ç±»ä¼¼çš„SPAåº”ç”¨
                if self._is_spa_application(soup):
                    logger.warning("æ£€æµ‹åˆ°SPAåº”ç”¨ï¼Œå¸–å­å†…å®¹å¯èƒ½é€šè¿‡JavaScriptåŠ¨æ€åŠ è½½")
                
                # é¦–å…ˆæ£€æŸ¥å¸–å­å®¹å™¨æ˜¯å¦ä¸ºç©º
                if self._is_posts_container_empty(soup):
                    logger.warning("å¸–å­å®¹å™¨ä¸ºç©ºï¼Œå¯èƒ½æ²¡æœ‰å¸–å­æ•°æ®æˆ–éœ€è¦JavaScriptæ¸²æŸ“")
                    return []
                
                # é¦–å…ˆå°è¯•è¯†åˆ«å¸¸è§çš„è®ºå›ç»“æ„
                # 1. å°è¯•æŸ¥æ‰¾æ˜ç¡®çš„å¸–å­å®¹å™¨
                post_containers = self._find_post_containers(soup)
                
                if post_containers:
                    logger.info(f"æ‰¾åˆ° {len(post_containers)} ä¸ªå¸–å­å®¹å™¨")
                    for container in post_containers:
                        post_data = self._extract_post_from_container(container)
                        if post_data and self._is_valid_post(post_data):
                            posts.append(post_data)
                
                # 2. å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜ç¡®çš„å®¹å™¨ï¼Œä½¿ç”¨æ”¹è¿›çš„é€šç”¨æ–¹æ³•
                if not posts:
                    logger.info("æœªæ‰¾åˆ°æ˜ç¡®çš„å¸–å­å®¹å™¨ï¼Œä½¿ç”¨é€šç”¨æ–¹æ³•")
                    posts = self._extract_posts_generic(soup)
                
                # 3. è¿‡æ»¤å’ŒéªŒè¯å¸–å­
                filtered_posts = []
                for post in posts:
                    if self._is_valid_post(post) and not self._is_excluded_content(post):
                        filtered_posts.append(post)
                
                # å»é‡
                unique_posts = self._deduplicate_posts(filtered_posts)
                
                logger.info(f"è·å–åˆ° {len(unique_posts)} ä¸ªæœ‰æ•ˆå¸–å­")
                return unique_posts
                
        except Exception as e:
            logger.error(f"è·å–è®ºå›å¸–å­å¤±è´¥: {e}")
            return []

    def _is_spa_application(self, soup: BeautifulSoup) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸ºå•é¡µåº”ç”¨"""
        # æŸ¥æ‰¾å¸¸è§çš„SPAæ¡†æ¶æ ‡è¯†
        spa_indicators = [
            'nuxt', 'vue', 'react', 'angular', '__NUXT_DATA__', 
            'data-nuxt-', 'ng-app', 'reactroot'
        ]
        
        html_content = str(soup).lower()
        return any(indicator in html_content for indicator in spa_indicators)
    
    def _is_posts_container_empty(self, soup: BeautifulSoup) -> bool:
        """æ£€æŸ¥å¸–å­å®¹å™¨æ˜¯å¦ä¸ºç©º"""
        # æŸ¥æ‰¾å¸–å­åˆ—è¡¨å®¹å™¨
        posts_containers = soup.find_all(['div', 'ul', 'section'], 
                                       class_=re.compile(r'(posts?[-_]?(list|container|wrapper)|forum[-_]?posts?|topic[-_]?list)', re.I))
        
        if not posts_containers:
            return True
        
        for container in posts_containers:
            # è·å–å®¹å™¨å†…çš„æ–‡æœ¬å†…å®¹ï¼ˆæ’é™¤HTMLæ ‡ç­¾ï¼‰
            text_content = container.get_text(strip=True)
            
            # å¦‚æœå®¹å™¨æœ‰æ„ä¹‰çš„æ–‡æœ¬å†…å®¹ï¼Œè¯´æ˜ä¸ä¸ºç©º
            if text_content and len(text_content) > 10:
                # ä½†è¦æ’é™¤åªåŒ…å«å¯¼èˆª/æŒ‰é’®æ–‡å­—çš„æƒ…å†µ
                if not self._is_only_navigation_content(text_content):
                    return False
        
        return True
    
    def _is_only_navigation_content(self, text: str) -> bool:
        """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åªåŒ…å«å¯¼èˆª/æŒ‰é’®å†…å®¹"""
        navigation_patterns = [
            r'^(ä¸Šä¸€é¡µ|ä¸‹ä¸€é¡µ|é¦–é¡µ|æœ«é¡µ|ç¬¬\s*\d+\s*é¡µ|å…±\s*\d+\s*é¡µ|é¡µç |åˆ†é¡µ)+$',
            r'^(å‘å¸–|æˆ‘è¦å‘å¸–|æ–°å»º|æ·»åŠ |åˆ›å»º|ç™»å½•|æ³¨å†Œ|æœç´¢|ç­›é€‰|æ’åº)+$',
            r'^(åŠ è½½ä¸­|loading|æš‚æ— æ•°æ®|æ²¡æœ‰æ›´å¤š|åˆ°åº•äº†)+$'
        ]
        
        text_clean = re.sub(r'\s+', '', text).lower()
        return any(re.search(pattern, text, re.I) for pattern in navigation_patterns)

    def _find_post_containers(self, soup: BeautifulSoup) -> List:
        """æŸ¥æ‰¾å¸–å­å®¹å™¨å…ƒç´ """
        containers = []
        
        # å¸¸è§çš„å¸–å­å®¹å™¨é€‰æ‹©å™¨
        selectors = [
            # åŸºäºç±»åçš„é€‰æ‹©å™¨
            '[class*="post"]:not([class*="button"]):not([class*="btn"])',
            '[class*="topic"]:not([class*="button"]):not([class*="btn"])',
            '[class*="thread"]:not([class*="button"]):not([class*="btn"])',
            '[class*="article"]:not([class*="button"]):not([class*="btn"])',
            '[class*="item"]:not([class*="nav"]):not([class*="menu"])',
            # åŸºäºæ•°æ®å±æ€§çš„é€‰æ‹©å™¨
            '[data-post-id]',
            '[data-topic-id]',
            '[data-thread-id]',
            # ç»“æ„åŒ–é€‰æ‹©å™¨
            'article[id*="post"]',
            'div[id*="post"]',
            'li[id*="post"]',
        ]
        
        for selector in selectors:
            try:
                elements = soup.select(selector)
                if elements:
                    logger.debug(f"é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(elements)} ä¸ªå…ƒç´ ")
                    containers.extend(elements)
                    if len(containers) >= 10:  # é™åˆ¶æ•°é‡é¿å…è¿‡å¤š
                        break
            except Exception as e:
                logger.debug(f"é€‰æ‹©å™¨ '{selector}' æ‰§è¡Œå¤±è´¥: {e}")
        
        return containers

    def _extract_post_from_container(self, container) -> Optional[Dict]:
        """ä»å®¹å™¨ä¸­æå–å¸–å­ä¿¡æ¯"""
        try:
            # æŸ¥æ‰¾æ ‡é¢˜é“¾æ¥
            title_link = None
            
            # ä¼˜å…ˆæŸ¥æ‰¾æ˜ç¡®çš„æ ‡é¢˜é“¾æ¥
            title_selectors = [
                'a[class*="title"]',
                'a[class*="subject"]',
                'a[class*="topic"]',
                'h1 a', 'h2 a', 'h3 a', 'h4 a',
                '.title a', '.subject a', '.topic a',
            ]
            
            for selector in title_selectors:
                try:
                    link = container.select_one(selector)
                    if link and link.get('href'):
                        title_link = link
                        break
                except:
                    continue
            
            # å¦‚æœæ²¡æ‰¾åˆ°ï¼ŒæŸ¥æ‰¾ç¬¬ä¸€ä¸ªæœ‰æ•ˆé“¾æ¥
            if not title_link:
                links = container.find_all('a', href=True)
                for link in links:
                    if self._looks_like_post_link(link):
                        title_link = link
                        break
            
            if not title_link:
                return None
            
            title = title_link.get_text(strip=True)
            href = title_link.get('href')
            
            # æ ‡å‡†åŒ–URL
            if href.startswith('/'):
                href = 'https://unikorn.axfff.com' + href
            elif not href.startswith('http'):
                href = 'https://unikorn.axfff.com/forum/' + href
            
            # æå–é¢å¤–ä¿¡æ¯
            post_data = {
                'title': title,
                'url': href,
                'id': href,
                'container_class': container.get('class', []),
                'container_id': container.get('id', ''),
            }
            
            # å°è¯•æå–å‘å¸ƒæ—¶é—´
            time_element = container.select_one('[class*="time"], [class*="date"], time')
            if time_element:
                post_data['timestamp'] = time_element.get_text(strip=True)
            
            return post_data
            
        except Exception as e:
            logger.debug(f"ä»å®¹å™¨æå–å¸–å­ä¿¡æ¯å¤±è´¥: {e}")
            return None

    def _extract_posts_generic(self, soup: BeautifulSoup) -> List[Dict]:
        """é€šç”¨çš„å¸–å­æå–æ–¹æ³•"""
        posts = []
        
        # æŸ¥æ‰¾æ‰€æœ‰é“¾æ¥
        all_links = soup.find_all('a', href=True)
        
        for link in all_links:
            if self._looks_like_post_link(link):
                href = link.get('href')
                title = link.get_text(strip=True)
                
                # æ ‡å‡†åŒ–URL
                if href.startswith('/'):
                    href = 'https://unikorn.axfff.com' + href
                elif not href.startswith('http'):
                    href = 'https://unikorn.axfff.com/forum/' + href
                
                posts.append({
                    'title': title,
                    'url': href,
                    'id': href,
                    'link_class': link.get('class', []),
                    'parent_class': link.parent.get('class', []) if link.parent else [],
                })
        
        return posts

    def _looks_like_post_link(self, link) -> bool:
        """åˆ¤æ–­é“¾æ¥æ˜¯å¦çœ‹èµ·æ¥åƒå¸–å­é“¾æ¥"""
        href = link.get('href', '')
        title = link.get_text(strip=True)
        
        # URLæ¨¡å¼æ£€æŸ¥
        url_patterns = [
            '/post/', '/topic/', '/thread/', '/discussion/',
            '/p/', '/t/', '/d/', '/forum/',
            r'/\d+/', r'id=\d+', r'tid=\d+', r'pid=\d+'
        ]
        
        import re
        url_matches = any(re.search(pattern, href) for pattern in url_patterns)
        
        # æ ‡é¢˜æ£€æŸ¥
        title_valid = (
            title and 
            len(title) > 5 and 
            len(title) < 200 and
            not self._is_button_text(title)
        )
        
        return url_matches and title_valid

    def _is_button_text(self, text: str) -> bool:
        """åˆ¤æ–­æ–‡æœ¬æ˜¯å¦ä¸ºæŒ‰é’®æ–‡æœ¬"""
        if not text or len(text.strip()) < 2:
            return True
            
        # è·å–ç”¨æˆ·é…ç½®çš„æ’é™¤å…³é”®è¯
        excluded_keywords = self.config.get("excluded_keywords", [])
        
        # ç²¾ç¡®åŒ¹é…çš„æŒ‰é’®æ–‡æœ¬æ¨¡å¼ï¼ˆå®Œå…¨åŒ¹é…ï¼‰
        exact_button_patterns = [
            # å‘å¸–ç›¸å…³
            r'^æˆ‘è¦å‘å¸–$', r'^å‘å¸ƒå¸–å­$', r'^æ–°å»ºå¸–å­$', r'^åˆ›å»ºå¸–å­$', r'^å†™å¸–å­$', r'^å‘å¸–$',
            # ç”¨æˆ·æ“ä½œ
            r'^ç™»å½•$', r'^æ³¨å†Œ$', r'^é€€å‡º$', r'^ç™»å‡º$', r'^æ³¨é”€$',
            # å¯¼èˆªæŒ‰é’®  
            r'^é¦–é¡µ$', r'^ä¸»é¡µ$', r'^è¿”å›$', r'^ä¸Šä¸€é¡µ$', r'^ä¸‹ä¸€é¡µ$', r'^æœ«é¡µ$', r'^å°¾é¡µ$',
            # åˆ†é¡µç›¸å…³
            r'^ç¬¬\s*\d+\s*é¡µ$', r'^å…±\s*\d+\s*é¡µ$', r'^é¡µç \s*\d+$',
            # åŠŸèƒ½æŒ‰é’®
            r'^æœç´¢$', r'^æŸ¥æ‰¾$', r'^ç­›é€‰$', r'^è¿‡æ»¤$', r'^æ’åº$', r'^åˆ‡æ¢$',
            r'^å±•å¼€$', r'^æ”¶èµ·$', r'^æ›´å¤š$', r'^è¯¦æƒ…$', r'^æŸ¥çœ‹$',
            # è¡¨å•æŒ‰é’®
            r'^æäº¤$', r'^ç¡®å®š$', r'^å–æ¶ˆ$', r'^é‡ç½®$', r'^ä¿å­˜$', r'^åˆ é™¤$',
            r'^ç¼–è¾‘$', r'^ä¿®æ”¹$', r'^æ·»åŠ $', r'^æ–°å¢$',
            # è‹±æ–‡æŒ‰é’®
            r'^post$', r'^new post$', r'^create$', r'^login$', r'^register$',
            r'^search$', r'^more$', r'^next$', r'^prev$', r'^home$',
        ]
        
        # é»˜è®¤åŒ…å«å…³é”®è¯ï¼ˆæ›´ä¿å®ˆçš„ç­–ç•¥ï¼Œé¿å…è¯¯åˆ¤æ­£å¸¸å¸–å­ï¼‰
        default_button_keywords = [
            'å›å¤', 'ç¼–è¾‘', 'åˆ é™¤', 'ä¸¾æŠ¥', 'ç‚¹èµ', 'æ”¶è—',
            'æäº¤', 'ç¡®å®š', 'å–æ¶ˆ', 'å…³é—­',
            'reply', 'edit', 'delete', 'report', 'like', 'save',
            'submit', 'ok', 'cancel', 'close',
        ]
        
        text_clean = text.strip()
        
        # é¦–å…ˆæ£€æŸ¥ç²¾ç¡®åŒ¹é…æ¨¡å¼
        for pattern in exact_button_patterns:
            if re.search(pattern, text_clean, re.IGNORECASE):
                return True
        
        # ç„¶åæ£€æŸ¥åŒ…å«å…³é”®è¯
        all_keywords = default_button_keywords + excluded_keywords
        text_lower = text_clean.lower()
        
        for keyword in all_keywords:
            if keyword.lower() in text_lower:
                return True
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºçº¯æ•°å­—ã€ç¬¦å·æˆ–å•å­—ç¬¦
        if re.match(r'^[\d\s\-_\+\.]+$|^.$', text_clean):
            return True
        
        return False

    def _is_valid_post(self, post_data: Dict) -> bool:
        """éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆå¸–å­"""
        if not post_data:
            return False
        
        title = post_data.get('title', '')
        url = post_data.get('url', '')
        
        # åŸºæœ¬æ£€æŸ¥
        if not title or not url:
            return False
        
        # ä½¿ç”¨é…ç½®çš„æ ‡é¢˜é•¿åº¦é™åˆ¶
        min_length = self.config.get("min_title_length", 5)
        max_length = self.config.get("max_title_length", 50) * 4  # ç”¨äºéªŒè¯çš„æœ€å¤§é•¿åº¦æ¯”æ˜¾ç¤ºé•¿åº¦æ›´é•¿
        
        if len(title) < min_length or len(title) > max_length:
            if self.config.get("debug_mode", False):
                logger.debug(f"æ ‡é¢˜é•¿åº¦ä¸ç¬¦åˆè¦æ±‚: '{title}' (é•¿åº¦: {len(title)})")
            return False
        
        # URLæœ‰æ•ˆæ€§æ£€æŸ¥
        if not url.startswith('http'):
            return False
        
        return True

    def _is_excluded_content(self, text: str) -> bool:
        """æ£€æŸ¥å†…å®¹æ˜¯å¦åº”è¢«æ’é™¤ï¼ˆæ”¹è¿›ç‰ˆï¼‰"""
        if not text:
            return True
        
        # è·å–ç”¨æˆ·é…ç½®çš„æ’é™¤å…³é”®è¯
        user_excluded = self.config.get("excluded_keywords", [])
        
        # ä¸¥æ ¼åŒ¹é…çš„æ’é™¤æ¨¡å¼ï¼ˆé¿å…è¯¯åˆ¤æ­£å¸¸å¸–å­ï¼‰
        strict_exclusion_patterns = [
            # å¯¼èˆªç±»ï¼ˆå®Œå…¨åŒ¹é…ï¼‰
            r'^(é¦–é¡µ|ä¸»é¡µ|ä¸Šä¸€é¡µ|ä¸‹ä¸€é¡µ|æœ«é¡µ|å°¾é¡µ)$',
            # åˆ†é¡µç±»
            r'^(ç¬¬\s*\d+\s*é¡µ|å…±\s*\d+\s*é¡µ|é¡µç ).*$',
            # åŠŸèƒ½ç±»ï¼ˆå®Œå…¨åŒ¹é…ï¼‰
            r'^(ç™»å½•|æ³¨å†Œ|æœç´¢|ç­›é€‰|æ’åº|è®¾ç½®|å¸®åŠ©|å…³äºæˆ‘ä»¬|è”ç³»æˆ‘ä»¬)$',
            r'^(æ’åºæ–¹å¼|ç­›é€‰æ¡ä»¶|æœç´¢ç»“æœ).*$',
            # èœå•ç±»
            r'^(èœå•|å¯¼èˆª|é¢åŒ…å±‘).*$',
        ]
        
        text_clean = text.strip()
        
        # æ£€æŸ¥ä¸¥æ ¼åŒ¹é…æ¨¡å¼
        for pattern in strict_exclusion_patterns:
            if re.search(pattern, text_clean, re.IGNORECASE):
                return True
        
        # æ£€æŸ¥ç”¨æˆ·è‡ªå®šä¹‰çš„æ’é™¤å…³é”®è¯ï¼ˆå¦‚æœç”¨æˆ·æ˜ç¡®é…ç½®äº†ï¼‰
        if user_excluded:
            text_lower = text_clean.lower()
            for keyword in user_excluded:
                if keyword.lower() in text_lower:
                    return True
        
        return False

    def _deduplicate_posts(self, posts: List[Dict]) -> List[Dict]:
        """å»é‡å¸–å­åˆ—è¡¨"""
        seen_urls = set()
        seen_titles = set()
        unique_posts = []
        
        for post in posts:
            url = post['url']
            title = post['title']
            
            # åŸºäºURLå»é‡
            if url in seen_urls:
                continue
            
            # åŸºäºæ ‡é¢˜å»é‡ï¼ˆå¤„ç†ç›¸åŒæ ‡é¢˜ä¸åŒURLçš„æƒ…å†µï¼‰
            title_normalized = title.lower().strip()
            if title_normalized in seen_titles:
                continue
            
            seen_urls.add(url)
            seen_titles.add(title_normalized)
            unique_posts.append(post)
        
        return unique_posts

    async def check_for_new_posts(self):
        """æ£€æŸ¥æ–°å¸–å­"""
        try:
            posts = await self.fetch_forum_posts()
            new_posts = []
            
            for post in posts:
                if post['id'] not in self.known_posts:
                    new_posts.append(post)
                    self.known_posts.add(post['id'])
            
            if new_posts:
                logger.info(f"å‘ç° {len(new_posts)} ä¸ªæ–°å¸–å­")
                await self.notify_new_posts(new_posts)
                await self.save_known_posts()
            else:
                logger.debug("æ²¡æœ‰å‘ç°æ–°å¸–å­")
                
        except Exception as e:
            logger.error(f"æ£€æŸ¥æ–°å¸–å­å¤±è´¥: {e}")

    async def notify_new_posts(self, new_posts: List[Dict]):
        """é€šçŸ¥æ–°å¸–å­"""
        try:
            target_groups = self.config.get("target_groups", [])
            max_title_length = self.config.get("max_title_length", 50)
            
            if not target_groups:
                logger.warning("æœªé…ç½®ç›®æ ‡QQç¾¤ï¼Œæ— æ³•æ¨é€æ–°å¸–å­")
                return
            
            for post in new_posts:
                title = post['title']
                if len(title) > max_title_length:
                    title = title[:max_title_length] + "..."
                
                message = f"ğŸ†• Unikornè®ºå›æ–°å¸–å­\n\nğŸ“ {title}\nğŸ”— {post['url']}"
                
                # å‘é€åˆ°æ¯ä¸ªé…ç½®çš„ç¾¤
                for group_id in target_groups:
                    try:
                        # æ„é€ æ¶ˆæ¯é“¾ - ä½¿ç”¨æ­£ç¡®çš„MessageChainæ–¹å¼
                        message_chain = MessageChain().message(message)
                        
                        # æ„é€ unified_msg_origin
                        unified_msg_origin = f"qq_group_{group_id}"
                        
                        # ä½¿ç”¨contextå‘é€æ¶ˆæ¯
                        await self.context.send_message(unified_msg_origin, message_chain)
                        logger.info(f"å·²å‘ç¾¤ {group_id} æ¨é€æ–°å¸–å­: {title}")
                    except Exception as e:
                        logger.error(f"å‘ç¾¤ {group_id} æ¨é€æ¶ˆæ¯å¤±è´¥: {e}")
                        
        except Exception as e:
            logger.error(f"é€šçŸ¥æ–°å¸–å­å¤±è´¥: {e}")

    async def start_monitoring(self):
        """å¯åŠ¨ç›‘æ§ä»»åŠ¡"""
        if self.check_task and not self.check_task.done():
            logger.warning("ç›‘æ§ä»»åŠ¡å·²åœ¨è¿è¡Œ")
            return
            
        interval = self.config.get("check_interval", 5) * 60  # è½¬æ¢ä¸ºç§’
        logger.info(f"å¯åŠ¨Unikornè®ºå›ç›‘æ§ï¼Œæ£€æŸ¥é—´éš”: {interval/60} åˆ†é’Ÿ")
        
        self.check_task = asyncio.create_task(self._monitoring_loop(interval))

    async def _monitoring_loop(self, interval: int):
        """ç›‘æ§å¾ªç¯"""
        while True:
            try:
                await self.check_for_new_posts()
                await asyncio.sleep(interval)
            except asyncio.CancelledError:
                logger.info("ç›‘æ§ä»»åŠ¡å·²å–æ¶ˆ")
                break
            except Exception as e:
                logger.error(f"ç›‘æ§å¾ªç¯å‡ºé”™: {e}")
                await asyncio.sleep(interval)

    @filter.command("unikorn")
    async def unikorn_command(self, event: AstrMessageEvent):
        """Unikornè®ºå›ç›‘æ§ç®¡ç†æŒ‡ä»¤"""
        admin_qq_list = self.config.get("admin_qq_list", [])
        sender_id = event.get_sender_id()
        is_admin = sender_id in admin_qq_list if admin_qq_list else False
        
        basic_commands = (
            "ğŸ“‹ åŸºæœ¬æŒ‡ä»¤:\n"
            "/unikorn status - æŸ¥çœ‹ç›‘æ§çŠ¶æ€\n"
            "/unikorn check - æ‰‹åŠ¨æ£€æŸ¥æ›´æ–°\n"
            "/unikorn start - å¯åŠ¨ç›‘æ§\n"
            "/unikorn stop - åœæ­¢ç›‘æ§\n"
            "/unikorn posts - æŸ¥çœ‹æœ€æ–°å¸–å­"
        )
        
        admin_commands = (
            "\n\nğŸ”§ ç®¡ç†å‘˜æŒ‡ä»¤ (éœ€é…ç½®admin_qq_list):\n"
            "/unikorn recall - åè®®ç«¯APIæ¼”ç¤ºï¼ˆæ¶ˆæ¯æ’¤å›ç­‰ï¼‰\n"
            "/unikorn groupmembers - è·å–ç¾¤æˆå‘˜ç»Ÿè®¡\n"
            "/unikorn debug - è°ƒè¯•å¸–å­ç­›é€‰æœºåˆ¶"
        )
        
        message = "ğŸ¦„ Unikornè®ºå›ç›‘æ§æ’ä»¶\n\n" + basic_commands
        
        if is_admin and event.get_platform_name() == "aiocqhttp":
            message += admin_commands
        elif admin_qq_list and event.get_platform_name() == "aiocqhttp":
            message += "\n\nğŸ’¡ æç¤º: æ‚¨ä¸åœ¨ç®¡ç†å‘˜åˆ—è¡¨ä¸­ï¼Œæ— æ³•ä½¿ç”¨é«˜çº§åŠŸèƒ½"
        elif event.get_platform_name() != "aiocqhttp":
            message += "\n\nğŸ’¡ æç¤º: åè®®ç«¯APIåŠŸèƒ½ä»…åœ¨QQå¹³å°(aiocqhttp)å¯ç”¨"
            
        yield event.plain_result(message)

    @filter.command("unikorn", "status")
    async def status_command(self, event: AstrMessageEvent):
        """æŸ¥çœ‹ç›‘æ§çŠ¶æ€"""
        is_running = self.check_task and not self.check_task.done()
        status = "è¿è¡Œä¸­" if is_running else "å·²åœæ­¢"
        interval = self.config.get("check_interval", 5)
        target_groups = self.config.get("target_groups", [])
        
        message = (f"ğŸ“Š Unikornè®ºå›ç›‘æ§çŠ¶æ€\n\n"
                  f"ğŸ”„ çŠ¶æ€: {status}\n"
                  f"â° æ£€æŸ¥é—´éš”: {interval} åˆ†é’Ÿ\n"
                  f"ğŸ‘¥ ç›®æ ‡ç¾¤: {len(target_groups)} ä¸ª\n"
                  f"ğŸ“š å·²çŸ¥å¸–å­: {len(self.known_posts)} ä¸ª")
        
        yield event.plain_result(message)

    @filter.command("unikorn", "check")
    async def manual_check_command(self, event: AstrMessageEvent):
        """æ‰‹åŠ¨æ£€æŸ¥æ›´æ–°"""
        yield event.plain_result("ğŸ” æ­£åœ¨æ£€æŸ¥Unikornè®ºå›æ›´æ–°...")
        
        try:
            await self.check_for_new_posts()
            yield event.plain_result("âœ… æ£€æŸ¥å®Œæˆï¼å¦‚æœ‰æ–°å¸–å­ä¼šè‡ªåŠ¨æ¨é€åˆ°é…ç½®çš„ç¾¤ã€‚")
        except Exception as e:
            logger.error(f"æ‰‹åŠ¨æ£€æŸ¥å¤±è´¥: {e}")
            yield event.plain_result(f"âŒ æ£€æŸ¥å¤±è´¥: {str(e)}")

    @filter.command("unikorn", "start")
    async def start_command(self, event: AstrMessageEvent):
        """å¯åŠ¨ç›‘æ§"""
        try:
            await self.start_monitoring()
            yield event.plain_result("âœ… Unikornè®ºå›ç›‘æ§å·²å¯åŠ¨")
        except Exception as e:
            logger.error(f"å¯åŠ¨ç›‘æ§å¤±è´¥: {e}")
            yield event.plain_result(f"âŒ å¯åŠ¨å¤±è´¥: {str(e)}")

    @filter.command("unikorn", "stop")
    async def stop_command(self, event: AstrMessageEvent):
        """åœæ­¢ç›‘æ§"""
        if self.check_task and not self.check_task.done():
            self.check_task.cancel()
            yield event.plain_result("â¹ï¸ Unikornè®ºå›ç›‘æ§å·²åœæ­¢")
        else:
            yield event.plain_result("â„¹ï¸ ç›‘æ§æœªåœ¨è¿è¡Œ")

    @filter.command("unikorn", "posts")
    async def posts_command(self, event: AstrMessageEvent):
        """æŸ¥çœ‹æœ€æ–°å¸–å­"""
        yield event.plain_result("ğŸ“– æ­£åœ¨è·å–æœ€æ–°å¸–å­...")
        
        try:
            posts = await self.fetch_forum_posts()
            if not posts:
                yield event.plain_result("âŒ æœªèƒ½è·å–åˆ°å¸–å­ï¼Œå¯èƒ½ç½‘ç«™ç»“æ„å‘ç”Ÿäº†å˜åŒ–")
                return
            
            # æ˜¾ç¤ºæœ€å¤š5ä¸ªæœ€æ–°å¸–å­
            display_posts = posts[:5]
            max_title_length = self.config.get("max_title_length", 50)
            
            message = "ğŸ“š Unikornè®ºå›æœ€æ–°å¸–å­:\n\n"
            for i, post in enumerate(display_posts, 1):
                title = post['title']
                if len(title) > max_title_length:
                    title = title[:max_title_length] + "..."
                message += f"{i}. {title}\nğŸ”— {post['url']}\n\n"
            
            if len(posts) > 5:
                message += f"... è¿˜æœ‰ {len(posts) - 5} ä¸ªå¸–å­"
                
            yield event.plain_result(message)
            
        except Exception as e:
            logger.error(f"è·å–å¸–å­å¤±è´¥: {e}")
            yield event.plain_result(f"âŒ è·å–å¤±è´¥: {str(e)}")

    @filter.command("unikorn", "recall")
    async def recall_command(self, event: AstrMessageEvent):
        """æ’¤å›æœ€åä¸€æ¡æœºå™¨äººæ¶ˆæ¯ï¼ˆä»…ç®¡ç†å‘˜ï¼‰- å±•ç¤ºaiocqhttpåè®®ç«¯APIçš„ä½¿ç”¨"""
        try:
            # æ£€æŸ¥æ˜¯å¦ä¸ºaiocqhttpå¹³å°
            if event.get_platform_name() != "aiocqhttp":
                yield event.plain_result("âŒ æ­¤åŠŸèƒ½ä»…æ”¯æŒQQå¹³å°ï¼ˆaiocqhttpï¼‰")
                return
            
            # æ£€æŸ¥ç®¡ç†å‘˜æƒé™ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥ä½¿ç”¨AstrBotçš„æƒé™ç³»ç»Ÿï¼‰
            admin_qq_list = self.config.get("admin_qq_list", [])
            sender_id = event.get_sender_id()
            
            if admin_qq_list and sender_id not in admin_qq_list:
                yield event.plain_result("âŒ ä»…ç®¡ç†å‘˜å¯ä»¥ä½¿ç”¨æ­¤åŠŸèƒ½")
                return
            
            # å¯¼å…¥aiocqhttpç›¸å…³ç±»å‹
            from astrbot.core.platform.sources.aiocqhttp.aiocqhttp_message_event import AiocqhttpMessageEvent
            
            # ç¡®è®¤è¿™æ˜¯aiocqhttpäº‹ä»¶
            if not isinstance(event, AiocqhttpMessageEvent):
                yield event.plain_result("âŒ æ— æ³•è·å–åè®®ç«¯å®¢æˆ·ç«¯")
                return
            
            # è·å–åè®®ç«¯å®¢æˆ·ç«¯
            client = event.bot
            
            # è¿™é‡Œæ¼”ç¤ºå‡ ä¸ªå¸¸ç”¨çš„åè®®ç«¯APIè°ƒç”¨
            yield event.plain_result("ğŸ” æ­£åœ¨æ¼”ç¤ºåè®®ç«¯APIè°ƒç”¨...")
            
            # 1. è·å–ç¾¤ä¿¡æ¯
            if event.message_obj.group_id:
                try:
                    group_info_payload = {
                        "group_id": int(event.message_obj.group_id)
                    }
                    group_info = await client.api.call_action('get_group_info', **group_info_payload)
                    logger.info(f"ç¾¤ä¿¡æ¯: {group_info}")
                    
                    yield event.plain_result(f"ğŸ“‹ å½“å‰ç¾¤ä¿¡æ¯:\n"
                                           f"ç¾¤å·: {group_info.get('group_id', 'N/A')}\n"
                                           f"ç¾¤å: {group_info.get('group_name', 'N/A')}\n"
                                           f"æˆå‘˜æ•°: {group_info.get('member_count', 'N/A')}")
                except Exception as e:
                    logger.error(f"è·å–ç¾¤ä¿¡æ¯å¤±è´¥: {e}")
                    yield event.plain_result(f"âŒ è·å–ç¾¤ä¿¡æ¯å¤±è´¥: {str(e)}")
            
            # 2. è·å–æœºå™¨äººè‡ªèº«ä¿¡æ¯
            try:
                login_info = await client.api.call_action('get_login_info')
                logger.info(f"ç™»å½•ä¿¡æ¯: {login_info}")
                
                yield event.plain_result(f"ğŸ¤– æœºå™¨äººä¿¡æ¯:\n"
                                       f"QQå·: {login_info.get('user_id', 'N/A')}\n"
                                       f"æ˜µç§°: {login_info.get('nickname', 'N/A')}")
            except Exception as e:
                logger.error(f"è·å–ç™»å½•ä¿¡æ¯å¤±è´¥: {e}")
                yield event.plain_result(f"âŒ è·å–ç™»å½•ä¿¡æ¯å¤±è´¥: {str(e)}")
            
            # 3. å‘é€ä¸€æ¡æµ‹è¯•æ¶ˆæ¯ï¼Œç„¶åæ¼”ç¤ºæ’¤å›
            try:
                # æ„é€ å‘é€æ¶ˆæ¯çš„å‚æ•°
                if event.message_obj.group_id:
                    send_payload = {
                        "group_id": int(event.message_obj.group_id),
                        "message": "ğŸ§ª è¿™æ˜¯ä¸€æ¡æµ‹è¯•æ¶ˆæ¯ï¼Œ3ç§’åå°†è¢«æ’¤å›..."
                    }
                    send_result = await client.api.call_action('send_group_msg', **send_payload)
                else:
                    send_payload = {
                        "user_id": int(event.get_sender_id()),
                        "message": "ğŸ§ª è¿™æ˜¯ä¸€æ¡æµ‹è¯•æ¶ˆæ¯ï¼Œ3ç§’åå°†è¢«æ’¤å›..."
                    }
                    send_result = await client.api.call_action('send_private_msg', **send_payload)
                
                logger.info(f"å‘é€æ¶ˆæ¯ç»“æœ: {send_result}")
                message_id = send_result.get('message_id')
                
                if message_id:
                    # ç­‰å¾…3ç§’
                    await asyncio.sleep(3)
                    
                    # æ’¤å›æ¶ˆæ¯
                    recall_payload = {
                        "message_id": message_id
                    }
                    recall_result = await client.api.call_action('delete_msg', **recall_payload)
                    logger.info(f"æ’¤å›æ¶ˆæ¯ç»“æœ: {recall_result}")
                    
                    yield event.plain_result("âœ… åè®®ç«¯APIè°ƒç”¨æ¼”ç¤ºå®Œæˆï¼æµ‹è¯•æ¶ˆæ¯å·²æ’¤å›ã€‚")
                else:
                    yield event.plain_result("âŒ æ— æ³•è·å–æ¶ˆæ¯IDï¼Œæ’¤å›æ¼”ç¤ºå¤±è´¥")
                    
            except Exception as e:
                logger.error(f"å‘é€/æ’¤å›æ¶ˆæ¯å¤±è´¥: {e}")
                yield event.plain_result(f"âŒ æ¶ˆæ¯æ“ä½œå¤±è´¥: {str(e)}")
            
        except Exception as e:
            logger.error(f"åè®®ç«¯APIè°ƒç”¨å¤±è´¥: {e}")
            yield event.plain_result(f"âŒ åè®®ç«¯APIè°ƒç”¨å¤±è´¥: {str(e)}")

    @filter.command("unikorn", "groupmembers")
    async def group_members_command(self, event: AstrMessageEvent):
        """è·å–ç¾¤æˆå‘˜åˆ—è¡¨ï¼ˆä»…ç®¡ç†å‘˜ï¼‰- å±•ç¤ºæ›´å¤šåè®®ç«¯API"""
        try:
            # æ£€æŸ¥å¹³å°å’Œæƒé™
            if event.get_platform_name() != "aiocqhttp":
                yield event.plain_result("âŒ æ­¤åŠŸèƒ½ä»…æ”¯æŒQQå¹³å°ï¼ˆaiocqhttpï¼‰")
                return
                
            admin_qq_list = self.config.get("admin_qq_list", [])
            sender_id = event.get_sender_id()
            
            if admin_qq_list and sender_id not in admin_qq_list:
                yield event.plain_result("âŒ ä»…ç®¡ç†å‘˜å¯ä»¥ä½¿ç”¨æ­¤åŠŸèƒ½")
                return
                
            if not event.message_obj.group_id:
                yield event.plain_result("âŒ æ­¤åŠŸèƒ½ä»…åœ¨ç¾¤èŠä¸­å¯ç”¨")
                return
            
            from astrbot.core.platform.sources.aiocqhttp.aiocqhttp_message_event import AiocqhttpMessageEvent
            
            if not isinstance(event, AiocqhttpMessageEvent):
                yield event.plain_result("âŒ æ— æ³•è·å–åè®®ç«¯å®¢æˆ·ç«¯")
                return
            
            client = event.bot
            
            # è·å–ç¾¤æˆå‘˜åˆ—è¡¨
            group_id = int(event.message_obj.group_id)
            member_list_payload = {
                "group_id": group_id
            }
            
            member_list = await client.api.call_action('get_group_member_list', **member_list_payload)
            logger.info(f"ç¾¤æˆå‘˜æ•°é‡: {len(member_list) if member_list else 0}")
            
            if member_list:
                # ç»Ÿè®¡ä¸åŒè§’è‰²çš„æˆå‘˜
                owners = [m for m in member_list if m.get('role') == 'owner']
                admins = [m for m in member_list if m.get('role') == 'admin']
                members = [m for m in member_list if m.get('role') == 'member']
                
                message = f"ğŸ‘¥ ç¾¤æˆå‘˜ç»Ÿè®¡ (ç¾¤å·: {group_id}):\n\n"
                message += f"ğŸ‘‘ ç¾¤ä¸»: {len(owners)} äºº\n"
                message += f"ğŸ›¡ï¸ ç®¡ç†å‘˜: {len(admins)} äºº\n"
                message += f"ğŸ‘¤ æ™®é€šæˆå‘˜: {len(members)} äºº\n"
                message += f"ğŸ“Š æ€»è®¡: {len(member_list)} äºº"
                
                yield event.plain_result(message)
            else:
                yield event.plain_result("âŒ è·å–ç¾¤æˆå‘˜åˆ—è¡¨å¤±è´¥")
                
        except Exception as e:
            logger.error(f"è·å–ç¾¤æˆå‘˜åˆ—è¡¨å¤±è´¥: {e}")
            yield event.plain_result(f"âŒ è·å–ç¾¤æˆå‘˜åˆ—è¡¨å¤±è´¥: {str(e)}")

    @filter.command("unikorn", "debug")
    async def debug_command(self, event: AstrMessageEvent):
        """è°ƒè¯•å¸–å­ç­›é€‰æœºåˆ¶ï¼ˆä»…ç®¡ç†å‘˜ï¼‰"""
        try:
            # æ£€æŸ¥æƒé™
            admin_qq_list = self.config.get("admin_qq_list", [])
            sender_id = event.get_sender_id()
            
            if admin_qq_list and sender_id not in admin_qq_list:
                yield event.plain_result("âŒ ä»…ç®¡ç†å‘˜å¯ä»¥ä½¿ç”¨æ­¤åŠŸèƒ½")
                return
            
            yield event.plain_result("ğŸ” å¼€å§‹è°ƒè¯•å¸–å­ç­›é€‰æœºåˆ¶...")
            
            # ä¸´æ—¶å¯ç”¨è°ƒè¯•æ¨¡å¼
            original_debug = self.config.get("debug_mode", False)
            self.config["debug_mode"] = True
            
            try:
                # è·å–åŸå§‹å¸–å­æ•°æ®
                if not self.session:
                    yield event.plain_result("âŒ HTTPä¼šè¯æœªåˆå§‹åŒ–")
                    return
                
                async with self.session.get(self.forum_url) as response:
                    if response.status != 200:
                        yield event.plain_result(f"âŒ è·å–è®ºå›é¡µé¢å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}")
                        return
                    
                    html = await response.text()
                    soup = BeautifulSoup(html, 'html.parser')
                    
                    # åˆ†æç½‘é¡µç»“æ„
                    debug_info = []
                    debug_info.append("ğŸ“Š ç½‘é¡µç»“æ„åˆ†æ:")
                    debug_info.append(f"æ€»é“¾æ¥æ•°: {len(soup.find_all('a', href=True))}")
                    debug_info.append(f"æ€»å…ƒç´ æ•°: {len(soup.find_all())}")
                    
                    # æŸ¥æ‰¾æ½œåœ¨çš„å¸–å­å®¹å™¨
                    containers = self._find_post_containers(soup)
                    debug_info.append(f"æ½œåœ¨å¸–å­å®¹å™¨: {len(containers)}")
                    
                    # è·å–æ‰€æœ‰é“¾æ¥è¿›è¡Œåˆ†æ
                    all_links = soup.find_all('a', href=True)
                    valid_links = []
                    invalid_links = []
                    
                    for link in all_links:
                        href = link.get('href', '')
                        title = link.get_text(strip=True)
                        
                        if self._looks_like_post_link(link):
                            valid_links.append({'title': title, 'href': href})
                        else:
                            invalid_links.append({'title': title, 'href': href})
                    
                    debug_info.append(f"ç–‘ä¼¼å¸–å­é“¾æ¥: {len(valid_links)}")
                    debug_info.append(f"æ’é™¤çš„é“¾æ¥: {len(invalid_links)}")
                    
                    # æ˜¾ç¤ºå‰å‡ ä¸ªæœ‰æ•ˆé“¾æ¥
                    debug_info.append("\nğŸ“ å‰5ä¸ªç–‘ä¼¼å¸–å­:")
                    for i, link in enumerate(valid_links[:5], 1):
                        debug_info.append(f"{i}. {link['title'][:30]}...")
                        debug_info.append(f"   URL: {link['href']}")
                    
                    # æ˜¾ç¤ºå‰å‡ ä¸ªè¢«æ’é™¤çš„é“¾æ¥
                    debug_info.append("\nâŒ å‰5ä¸ªè¢«æ’é™¤çš„é“¾æ¥:")
                    for i, link in enumerate(invalid_links[:5], 1):
                        debug_info.append(f"{i}. {link['title'][:30]}...")
                        debug_info.append(f"   URL: {link['href']}")
                    
                    # æµ‹è¯•å®Œæ•´çš„ç­›é€‰æµç¨‹
                    posts = await self.fetch_forum_posts()
                    debug_info.append(f"\nâœ… æœ€ç»ˆç­›é€‰ç»“æœ: {len(posts)} ä¸ªæœ‰æ•ˆå¸–å­")
                    
                    if posts:
                        debug_info.append("\nğŸ“‹ æœ€ç»ˆå¸–å­åˆ—è¡¨:")
                        for i, post in enumerate(posts[:3], 1):
                            debug_info.append(f"{i}. {post['title']}")
                    
                    # é…ç½®ä¿¡æ¯
                    debug_info.append(f"\nâš™ï¸ å½“å‰ç­›é€‰é…ç½®:")
                    debug_info.append(f"æœ€å°æ ‡é¢˜é•¿åº¦: {self.config.get('min_title_length', 5)}")
                    debug_info.append(f"ä¸¥æ ¼è¿‡æ»¤: {self.config.get('strict_filtering', True)}")
                    debug_info.append(f"æ’é™¤å…³é”®è¯: {len(self.config.get('excluded_keywords', []))}")
                    
                    yield event.plain_result("\n".join(debug_info))
                    
            finally:
                # æ¢å¤åŸå§‹è°ƒè¯•æ¨¡å¼è®¾ç½®
                self.config["debug_mode"] = original_debug
                
        except Exception as e:
            logger.error(f"è°ƒè¯•åŠŸèƒ½å¤±è´¥: {e}")
            yield event.plain_result(f"âŒ è°ƒè¯•å¤±è´¥: {str(e)}")

    async def terminate(self):
        """æ’ä»¶é”€æ¯æ–¹æ³•"""
        try:
            if self.check_task and not self.check_task.done():
                self.check_task.cancel()
                try:
                    await self.check_task
                except asyncio.CancelledError:
                    pass
            
            if self.session and not self.session.closed:
                await self.session.close()
                
            await self.save_known_posts()
            logger.info("Unikorn News Plugin å·²æ¸…ç†å®Œæˆ")
        except Exception as e:
            logger.error(f"æ’ä»¶æ¸…ç†å¤±è´¥: {e}")
